{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data.npy', 'labels.npy']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import SeparableConv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "\n",
    "    class SkinNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        \n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "\n",
    "       \n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "\n",
    "        model.add(SeparableConv2D(32, (3, 3), padding=\"same\",\n",
    "            input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(SeparableConv2D(32, (3, 3), padding=\"same\",\n",
    "            input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.10))\n",
    "\n",
    "        # (CONV => RELU => POOL) * 2\n",
    "        model.add(SeparableConv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(SeparableConv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(SeparableConv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(SeparableConv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.30))\n",
    "\n",
    "\n",
    "        model.add(SeparableConv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(SeparableConv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(SeparableConv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(SeparableConv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(SeparableConv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "6a75e8a465a26feaaab43522ad419809a7dce5e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\r\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/0c/659c2bdae8e8ca5ef810b9da02db28feaa29ea448ff36b65a1664ff28142/imutils-0.5.2.tar.gz\r\n",
      "Building wheels for collected packages: imutils\r\n",
      "  Building wheel for imutils (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/b2/40/59/139d450e68847ef2f27d876d527b13389dac23df0f66526b5d\r\n",
      "Successfully built imutils\r\n",
      "Installing collected packages: imutils\r\n",
      "Successfully installed imutils-0.5.2\r\n",
      "Load images' NPY file\n",
      "Compiling model...\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Training network\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/32\n",
      "52/52 [==============================] - 16s 313ms/step - loss: 0.6941 - acc: 0.7500 - val_loss: 0.9667 - val_acc: 0.7079\n",
      "Epoch 2/32\n",
      "52/52 [==============================] - 11s 208ms/step - loss: 0.4932 - acc: 0.7875 - val_loss: 4.1094 - val_acc: 0.5771\n",
      "Epoch 3/32\n",
      "52/52 [==============================] - 11s 206ms/step - loss: 0.4857 - acc: 0.7830 - val_loss: 1.5334 - val_acc: 0.5860\n",
      "Epoch 4/32\n",
      "52/52 [==============================] - 11s 209ms/step - loss: 0.4422 - acc: 0.7986 - val_loss: 0.8261 - val_acc: 0.7652\n",
      "Epoch 5/32\n",
      "52/52 [==============================] - 11s 208ms/step - loss: 0.4275 - acc: 0.8133 - val_loss: 0.4221 - val_acc: 0.8011\n",
      "Epoch 6/32\n",
      "52/52 [==============================] - 11s 207ms/step - loss: 0.4241 - acc: 0.8040 - val_loss: 2.0574 - val_acc: 0.6935\n",
      "Epoch 7/32\n",
      "52/52 [==============================] - 11s 207ms/step - loss: 0.3712 - acc: 0.8305 - val_loss: 0.7979 - val_acc: 0.7007\n",
      "Epoch 8/32\n",
      "52/52 [==============================] - 11s 208ms/step - loss: 0.3729 - acc: 0.8359 - val_loss: 0.4907 - val_acc: 0.8136\n",
      "Epoch 9/32\n",
      "52/52 [==============================] - 11s 210ms/step - loss: 0.3617 - acc: 0.8374 - val_loss: 0.7066 - val_acc: 0.7222\n",
      "Epoch 10/32\n",
      "52/52 [==============================] - 11s 207ms/step - loss: 0.3351 - acc: 0.8491 - val_loss: 0.7776 - val_acc: 0.8190\n",
      "Epoch 11/32\n",
      "52/52 [==============================] - 11s 208ms/step - loss: 0.3464 - acc: 0.8419 - val_loss: 0.8047 - val_acc: 0.7939\n",
      "Epoch 12/32\n",
      "52/52 [==============================] - 11s 208ms/step - loss: 0.3475 - acc: 0.8422 - val_loss: 1.2560 - val_acc: 0.6613\n",
      "Epoch 13/32\n",
      "52/52 [==============================] - 11s 207ms/step - loss: 0.3327 - acc: 0.8575 - val_loss: 1.3043 - val_acc: 0.7222\n",
      "Epoch 14/32\n",
      "52/52 [==============================] - 11s 208ms/step - loss: 0.3322 - acc: 0.8365 - val_loss: 0.6190 - val_acc: 0.7545\n",
      "Epoch 15/32\n",
      "52/52 [==============================] - 11s 210ms/step - loss: 0.3244 - acc: 0.8611 - val_loss: 0.9506 - val_acc: 0.6756\n",
      "Epoch 16/32\n",
      "52/52 [==============================] - 11s 208ms/step - loss: 0.3407 - acc: 0.8359 - val_loss: 0.6335 - val_acc: 0.7599\n",
      "Epoch 17/32\n",
      "52/52 [==============================] - 11s 208ms/step - loss: 0.3538 - acc: 0.8404 - val_loss: 0.6604 - val_acc: 0.7222\n",
      "Epoch 18/32\n",
      "52/52 [==============================] - 11s 208ms/step - loss: 0.3350 - acc: 0.8530 - val_loss: 0.3636 - val_acc: 0.8262\n",
      "Epoch 19/32\n",
      "52/52 [==============================] - 11s 208ms/step - loss: 0.3095 - acc: 0.8563 - val_loss: 0.7719 - val_acc: 0.6792\n",
      "Epoch 20/32\n",
      "52/52 [==============================] - 11s 209ms/step - loss: 0.3261 - acc: 0.8563 - val_loss: 0.3587 - val_acc: 0.8405\n",
      "Epoch 21/32\n",
      "52/52 [==============================] - 11s 208ms/step - loss: 0.3212 - acc: 0.8563 - val_loss: 0.3658 - val_acc: 0.8208\n",
      "Epoch 22/32\n",
      "52/52 [==============================] - 11s 207ms/step - loss: 0.3095 - acc: 0.8717 - val_loss: 0.3866 - val_acc: 0.8172\n",
      "Epoch 23/32\n",
      "52/52 [==============================] - 11s 207ms/step - loss: 0.3064 - acc: 0.8572 - val_loss: 0.3391 - val_acc: 0.8710\n",
      "Epoch 24/32\n",
      "52/52 [==============================] - 11s 208ms/step - loss: 0.3347 - acc: 0.8509 - val_loss: 0.3870 - val_acc: 0.8262\n",
      "Epoch 25/32\n",
      "52/52 [==============================] - 11s 207ms/step - loss: 0.2845 - acc: 0.8810 - val_loss: 0.4163 - val_acc: 0.8280\n",
      "Epoch 26/32\n",
      "52/52 [==============================] - 11s 205ms/step - loss: 0.2984 - acc: 0.8684 - val_loss: 0.8679 - val_acc: 0.7616\n",
      "Epoch 27/32\n",
      "52/52 [==============================] - 11s 208ms/step - loss: 0.3085 - acc: 0.8653 - val_loss: 0.3833 - val_acc: 0.8315\n",
      "Epoch 28/32\n",
      "52/52 [==============================] - 11s 208ms/step - loss: 0.3195 - acc: 0.8560 - val_loss: 0.3620 - val_acc: 0.8459\n",
      "Epoch 29/32\n",
      "52/52 [==============================] - 11s 208ms/step - loss: 0.3008 - acc: 0.8596 - val_loss: 0.5870 - val_acc: 0.7688\n",
      "Epoch 30/32\n",
      "52/52 [==============================] - 11s 207ms/step - loss: 0.3097 - acc: 0.8590 - val_loss: 0.3558 - val_acc: 0.8262\n",
      "Epoch 31/32\n",
      "52/52 [==============================] - 11s 206ms/step - loss: 0.3027 - acc: 0.8656 - val_loss: 0.4296 - val_acc: 0.7903\n",
      "Epoch 32/32\n",
      "52/52 [==============================] - 11s 208ms/step - loss: 0.3182 - acc: 0.8497 - val_loss: 0.5354 - val_acc: 0.7760\n",
      "Save the model for the applied CNN\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.96      0.81       279\n",
      "           1       0.94      0.59      0.72       279\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       558\n",
      "   macro avg       0.82      0.78      0.77       558\n",
      "weighted avg       0.82      0.78      0.77       558\n",
      "\n",
      "[[269  10]\n",
      " [115 164]]\n",
      "acc: 0.7760\n",
      "sensitivity: 0.9642\n",
      "specificity: 0.5878\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from keras import backend as K\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "\n",
    "\n",
    "EPOCHS = 32\n",
    "INIT_LR = 1e-3 #Initial Learning rate\n",
    "BS = 32 # Bach size to feed\n",
    "\n",
    "# initialize the data and labels\n",
    "print(\"Load images' NPY file\")\n",
    "data = []\n",
    "labels = []\n",
    "random.seed(42)\n",
    "#random.shuffle(imagePaths)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "data=np.load('../input/data.npy')\n",
    "labels=np.load('../input/labels.npy')\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "\tlabels, test_size=0.25, random_state=6)\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "trainY = to_categorical(trainY, num_classes=2)\n",
    "testY = to_categorical(testY, num_classes=2)\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# initialize the model\n",
    "print(\"Compiling model...\")\n",
    "model = SkinNet.build(width=128, height=128, depth=3, classes=2)\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS) #Optimise uisng Adam \n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "    \n",
    "# train the network\n",
    "print(\"Training network\")\n",
    "#checkpointer = ModelCheckpoint('model-dsbowl2018-1.h5', verbose=1, save_best_only=True)\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
    "\tvalidation_data=(testX, testY), steps_per_epoch=len(trainX)//BS,\n",
    "\tepochs=EPOCHS, verbose=1,callbacks=[tensorboard])\n",
    "\n",
    "label_name=[\"benign\",\"malicious\"]\n",
    "\n",
    "\n",
    "# save the model to disk\n",
    "print(\"Save the model for the applied CNN\")\n",
    "#model.save(args[\"model.hdf5\"])\n",
    "\n",
    "\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=128) #Check this\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "predictions.argmax(axis=1)))\n",
    "\n",
    "cm = confusion_matrix(testY.argmax(axis=1), predictions.argmax(axis=1))\n",
    "total = sum(sum(cm))\n",
    "acc = (cm[0, 0] + cm[1, 1]) / total\n",
    "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "print(cm)\n",
    "print(\"acc: {:.4f}\".format(acc))\n",
    "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
    "print(\"specificity: {:.4f}\".format(specificity))\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "0143869c03f560744822f661a94596b22f85400c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
